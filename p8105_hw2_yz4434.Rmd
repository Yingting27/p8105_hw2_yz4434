---
title: "Homework"
output: github_document
---

```{r}
library(tidyverse)
library(readxl)
```

# Problem 1

We clean the 538 `pols` data, which provides information on the number of national politicians who are democratic or republican at any given time. There are some values for which `prez_gop` is `2` -- these are months in which Ford became President following Nixon's resignation. In the new `president` variable created as part of our data cleaning, we code these as `gop` (same as values when `prez_gop` is `1`).

```{r clean_538_pols}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

We also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.

```{r clean_538_snp}
snp = 
  read_csv(
    "data/fivethirtyeight_datasets/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r clean_538_unemp}
unemployment = 
  read_csv("data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the 538 datasets. The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r pols |> pull(year) |> min()` to `r pols |> pull(year) |> max()`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r snp |> pull(year) |> min()` to `r snp |> pull(year) |> max()`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r unemployment |> pull(year) |> min()` to `r unemployment |> pull(year) |> max()`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.


## Question 2
```{r}
mr_trash_wheel_df = 
  readxl::read_excel("data/202309_Trash_Wheel_Collection_Data.xlsx", sheet = 1, range = "A2:N586") |>
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    homes_powered = weight_tons*500/30,
    trash_wheel_types = "Mr_trash_wheel"
  )
mr_trash_wheel_df$year = as.character(mr_trash_wheel_df$year)
```

# Import, clean, and organize the data for Professor Trash Wheel and Gwynnda

* Professor Trash Wheel

```{r}
prof_trash_wheel_df = 
  readxl::read_excel("data/202309_Trash_Wheel_Collection_Data.xlsx", sheet = 2, range = "A2:M108") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    homes_powered = weight_tons*500/30,
    trash_wheel_types = "professor_trash_wheel"
  )
prof_trash_wheel_df$year = as.character(prof_trash_wheel_df$year)
```


* Gwynnda Trash Wheel

```{r}
gwy_trash_wheel_df = 
  readxl::read_excel("data/202309_Trash_Wheel_Collection_Data.xlsx", sheet = 4, range = "A2:L157") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    homes_powered = weight_tons*500/30,
    trash_wheel_types = "Gwynnda_trash_wheel"
  )
gwy_trash_wheel_df$year = as.character(gwy_trash_wheel_df$year)
```


## Merging

```{r}
combine_sheet_df = 
  bind_rows(mr_trash_wheel_df,prof_trash_wheel_df,gwy_trash_wheel_df) |>
  janitor::clean_names() |> 
  relocate(trash_wheel_types)
```

* Calculate the total number of cigarette butts in 07/2021
```{r}
total_cigarettes = filter(gwy_trash_wheel_df, year == "2021", month == "July")
```


* Descriptions:
According to the results of combine sheet, we can see that there are **`r nrow(combine_sheet_df)` rows**, with **`r ncol(combine_sheet_df)` columns** in total. The key variables include **`r names(combine_sheet_df)`**. The total weight of trash collected by Professor Trash Wheel is **`r sum(prof_trash_wheel_df$weight_tons)`**. The total number of cigarette butts collected by Gwynnda in July of 2021 is **`r sum(total_cigarettes$cigarette_butts)`**

# Question 3

## Import dataset
```{r}
baseline_df =
  read_csv("data/MCI_baseline.csv", skip =1) |> 
  janitor::clean_names() |> 
  filter (current_age < age_at_onset | age_at_onset == ".") |> 
    mutate(
    sex = case_match(
      sex,
      1 ~ "male",
      0 ~ "female"
      )
) |> 
    mutate(
    apoe4 = case_match(
        apoe4,
        1 ~ "APOE4_carrier",
        0 ~ "APOE4_non_carrier"
      )
)
```

* Discuss important steps in the import process and relevant features of the dataset.

At first, I delete the first row as this is label but not data, which is not contained variable names for each column, using **skip function**. Then, I omit the data of those participants who didn't meet the inclusion criteria (the data of current ages are larger than the data of age at onset and those who don't develop MCI), since the study need to follow up participants and to see the situation that thy developed disease, using **filter function to keep data that current_age < age_at_onset and have data with age at onset**. Next, since the original data used numeric data, including 0 and 1 to mention sex and APOE4, I regard 1 as male, 0 as female, and 1 as APOE4 carrier with 0 as APOE4 non-carrier,using **mutate and case_match functions**. After that, there are **`r nrow(baseline_df)`** observations in the merged dataset. The key variables are **`r names(baseline_df)`**.

* How many participants were recruited, and of these how many develop MCI? 
```{r}
baseline_2 = filter(baseline_df, age_at_onset != ".")
```

There are **`r nrow(baseline_df)`** participants that were recruited, and **`r nrow(baseline_2)`** of these develop MCI.

* What is the average baseline age? 
```{r}
baseline_df$age_at_onset = as.numeric(baseline_df$current_age)
```

The average baseline age is **`r mean(baseline_df$current_age)`**. The proportion of women in the study are APOE4 carriers

* What proportion of women in the study are APOE4 carriers?

```{r}
prop_women = sum(baseline_df$sex == "female" & baseline_df$apoe4 == "APOE4_carrier") / sum(baseline_df$sex == "female")
```

The proportion of **`r prop_women`** women in the study are APOE4 carriers


# Import, clean, and tidy the dataset of mci_amyloid

```{r}
amyloid_df =
  read_csv("data/mci_amyloid.csv", skip =1) |> 
  janitor::clean_names() |> 
    pivot_longer(
    baseline:time_8,
    names_to = "time",
    values_to = "time_values",
    names_prefix = "time_"
  ) |> 
  rename(id = study_id) |> 
  mutate(time = replace(time, time == "baseline", "0")
)
```

* Comment on the steps on the import process and the features of the dataset

Firstly, I skip the first row as this line is not the titles of each columns, which
is just a label that is not useful in R studio after importing, using **skip function**. Secondly, I use **pivot function** to make wide format to be long format, which is more convenient to read and compare data. Thirdly, I change the time descriptions by using numeric way, like 0, 2, 4, 6, 8, by using **mutate and replace function**. After doing that, there are **`r nrow(amyloid_df)`** observations in the merged dataset. The key variables are **`r names(amyloid_df)`**.


# Combine datasets

* Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset
```{r}
mci_combine = 
  inner_join(baseline_df, amyloid_df, by = "id") |>
  janitor::clean_names()
```
There are **`r nrow(mci_combine)`** observations in the merged file, with important variables including **`r names(mci_combine)`**.

* Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings.

```{r}
mci_difference1 = anti_join(amyloid_df, baseline_df, by = "id")
mci_difference2 = anti_join(baseline_df, amyloid_df, by = "id")
```

There are **`r (nrow(mci_difference1)/5)`** observations in only the amyloid datasets, with **`r nrow(mci_difference2)`** observations in only the baseline datasets.

* Export the result as a CSV to your data directory.
```{r}
write.csv(mci_combine, "data/mci_combine.csv")
```



